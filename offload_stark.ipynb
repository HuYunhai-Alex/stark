{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/stark/lib/python3.11/site-packages/outdated/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: faiss must be imported for indexing\n",
      "Use file from /workspace/.hf_home/hub/datasets--snap-stanford--stark/snapshots/88269e23e90587f99476c5dd74e235a0877e69be/qa/amazon/stark_qa/stark_qa_human_generated_eval.csv.\n",
      "Loading from /workspace/.hf_home/hub/datasets--snap-stanford--stark/snapshots/88269e23e90587f99476c5dd74e235a0877e69be/skb/amazon/processed!\n",
      "Loading cached graph with meta link types ['brand', 'category', 'color']\n"
     ]
    }
   ],
   "source": [
    "from stark_qa import load_qa, load_skb\n",
    "\n",
    "dataset_name = 'amazon'\n",
    "qa_dataset = load_qa(dataset_name, \"/workspace/yunhai/stark/stark\")\n",
    "skb = load_skb(dataset_name, download_processed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load QA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Looking for a user-friendly fly fishing knot guide with clear, easy-to-understand illustrations. Ideally, it should be logically organised for easy learning and effective in teaching dependable knot tying techniques. It would be a bonus if it complements the Anglers Accessories Gehrke's Gink that I frequently use. Any recommendations?\n",
      "Query ID: 1\n",
      "Answer:\n",
      " Lake Products THREE-in-One Knot Tying Tool Fly Fishing\n",
      "EZ Tie Blood Knot Tying Tool\n",
      "BenchMaster Pocket Guide - Fly Fishing - Fishing\n"
     ]
    }
   ],
   "source": [
    "# Get one qa pair, we masked out metadata to avoid answer leaking\n",
    "query, q_id, answer_ids, _ = qa_dataset[1]\n",
    "print('Query:', query)\n",
    "print('Query ID:', q_id)\n",
    "print('Answer:\\n', '\\n'.join([skb[aid].title for aid in answer_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 5910\n",
      "Number of validation examples: 1548\n",
      "Number of test examples: 1642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': tensor([3885, 4522, 2110,  ..., 6839, 3967, 2814]),\n",
       " 'val': tensor([1550, 1486, 6591,  ..., 5606, 1204, 3792]),\n",
       " 'test': tensor([2905, 3863, 4651,  ..., 3891, 7631, 4472]),\n",
       " 'test-0.1': tensor([   3,   85,  135,  173,  214,  222,  290,  291,  372,  601,  750,  755,\n",
       "          788,  795,  850,  860,  861,  957, 1080, 1133, 1249, 1330, 1334, 1362,\n",
       "         1398, 1436, 1524, 1605, 1676, 1815, 1842, 1846, 1938, 1945, 1973, 1991,\n",
       "         2109, 2117, 2154, 2173, 2186, 2202, 2254, 2415, 2441, 2653, 2679, 2753,\n",
       "         2759, 2787, 2856, 2992, 3002, 3061, 3123, 3198, 3211, 3293, 3352, 3411,\n",
       "         3449, 3472, 3724, 3863, 3903, 3913, 4018, 4094, 4270, 4344, 4382, 4398,\n",
       "         4512, 4568, 4614, 4636, 4637, 4640, 4646, 4811, 4942, 4997, 5001, 5129,\n",
       "         5161, 5227, 5413, 5433, 5454, 5677, 5696, 5850, 5863, 5915, 5945, 5965,\n",
       "         6035, 6072, 6094, 6246, 6289, 6312, 6321, 6336, 6369, 6418, 6425, 6609,\n",
       "         6612, 6621, 6716, 6733, 6753, 6766, 6793, 6829, 6876, 6905, 6915, 7072,\n",
       "         7080, 7175, 7260, 7265, 7278, 7328, 7353, 7365, 7478, 7506, 7548, 7631,\n",
       "         7676, 7684, 7697, 7850, 7856, 7896, 8050, 8081, 8120, 8178, 8195, 8273,\n",
       "         8277, 8281, 8322, 8358, 8394, 8424, 8426, 8443, 8590, 8600, 8694, 8713,\n",
       "         8785, 8900, 8916, 8985, 9010, 9053, 9071, 9092])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We provide official random split for training, validation and test\n",
    "print('Number of training examples:', len(qa_dataset.get_subset('train')))\n",
    "print('Number of validation examples:', len(qa_dataset.get_subset('val')))\n",
    "print('Number of test examples:', len(qa_dataset.get_subset('test')))\n",
    "\n",
    "# Alternatively, you can get the split indices\n",
    "qa_dataset.get_idx_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load QA dataset - Human generated split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use file from /workspace/.hf_home/hub/datasets--snap-stanford--stark/snapshots/88269e23e90587f99476c5dd74e235a0877e69be/qa/amazon/stark_qa/stark_qa_human_generated_eval.csv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We provide a human generated evaluation set\n",
    "qa_dataset_hg = load_qa(dataset_name, human_generated_eval=True)\n",
    "len(qa_dataset_hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ 导出实体及其字段 …\n",
      "→ 实体导出完成，开始导出关系 …\n",
      "√ 导出完成，数据库保存在 stark_amazon.db\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# export_stark_to_sqlite.py\n",
    "\n",
    "import sqlite3\n",
    "import json\n",
    "import math\n",
    "from stark_qa import load_skb\n",
    "\n",
    "\n",
    "def to_text(x):\n",
    "    \"\"\"\n",
    "    将任意值转换为 SQLite 可存储的文本：\n",
    "      - None 或 NaN -> 空字符串\n",
    "      - 基本类型 (str/int/float) -> str(x)\n",
    "      - 列表或字典 -> JSON 字符串（使用 default=str 以处理嵌套 NaN）\n",
    "    \"\"\"\n",
    "    # None\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    # NaN (float) 检测\n",
    "    if isinstance(x, float) and (math.isnan(x)):\n",
    "        return \"\"\n",
    "    # 基本类型\n",
    "    if isinstance(x, (str, int, float)):\n",
    "        return str(x)\n",
    "    # 其他（如 list, dict）\n",
    "    try:\n",
    "        return json.dumps(x, ensure_ascii=False, default=str)\n",
    "    except Exception:\n",
    "        return str(x)\n",
    "\n",
    "\n",
    "def create_tables(conn):\n",
    "    c = conn.cursor()\n",
    "    # 实体表，包含所有指定的字段\n",
    "    c.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS entity (\n",
    "      id               INTEGER PRIMARY KEY,\n",
    "      review           TEXT,\n",
    "      qa               TEXT,\n",
    "      asin             TEXT,\n",
    "      title            TEXT,\n",
    "      global_category  TEXT,\n",
    "      category         TEXT,\n",
    "      price            TEXT,\n",
    "      brand            TEXT,\n",
    "      rank             INTEGER,\n",
    "      details          TEXT,\n",
    "      description      TEXT\n",
    "    );\n",
    "    \"\"\")\n",
    "    # 特征表，用于存储 feature 列表\n",
    "    c.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS feature (\n",
    "      entity_id     INTEGER,\n",
    "      feature_order INTEGER,\n",
    "      feature_text  TEXT,\n",
    "      PRIMARY KEY(entity_id, feature_order),\n",
    "      FOREIGN KEY(entity_id) REFERENCES entity(id)\n",
    "    );\n",
    "    \"\"\")\n",
    "    # 关系表，存储所有边\n",
    "    c.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS relation (\n",
    "      src_id   INTEGER,\n",
    "      dst_id   INTEGER,\n",
    "      rel_type TEXT,\n",
    "      PRIMARY KEY(src_id, dst_id, rel_type),\n",
    "      FOREIGN KEY(src_id) REFERENCES entity(id),\n",
    "      FOREIGN KEY(dst_id) REFERENCES entity(id)\n",
    "    );\n",
    "    \"\"\")\n",
    "    # 索引\n",
    "    c.execute(\"CREATE INDEX IF NOT EXISTS idx_rel_src ON relation(src_id);\")\n",
    "    c.execute(\"CREATE INDEX IF NOT EXISTS idx_rel_dst ON relation(dst_id);\")\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def export_skb_to_sqlite(skb, sqlite_path=\"stark_amazon.db\"):\n",
    "    conn = sqlite3.connect(sqlite_path)\n",
    "    create_tables(conn)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    print(\"→ 导出实体及其字段 …\")\n",
    "    for idx in range(1000):\n",
    "        node = skb[idx]\n",
    "        eid = idx\n",
    "        # 读取并转换所有指定字段\n",
    "        review          = to_text(getattr(node, \"review\", None))\n",
    "        qa              = to_text(getattr(node, \"qa\", None))\n",
    "        asin            = to_text(getattr(node, \"asin\", None))\n",
    "        title           = to_text(getattr(node, \"title\", None))\n",
    "        global_category = to_text(getattr(node, \"global_category\", None))\n",
    "        category        = to_text(getattr(node, \"category\", None))\n",
    "        price_raw       = getattr(node, \"price\", None)\n",
    "        brand           = to_text(getattr(node, \"brand\", None))\n",
    "        rank_raw        = getattr(node, \"rank\", None)\n",
    "        rank            = int(rank_raw)     if (rank_raw  is not None and str(rank_raw).isdigit()) else None\n",
    "        details         = to_text(getattr(node, \"details\", None))\n",
    "        description     = to_text(getattr(node, \"description\", None))\n",
    "\n",
    "        # 插入 entity\n",
    "        c.execute(\n",
    "          \"\"\"\n",
    "            INSERT OR IGNORE INTO entity(\n",
    "              id, review, qa, asin, title, global_category,\n",
    "              category, price, brand, rank, details, description\n",
    "            ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?)\n",
    "          \"\"\",\n",
    "          (\n",
    "            eid, review, qa, asin, title, global_category,\n",
    "            category, price_raw, brand, rank, details, description\n",
    "          )\n",
    "        )\n",
    "\n",
    "        # 插入 feature 列表\n",
    "        feats = getattr(node, \"feature\", [])\n",
    "        for order, ft in enumerate(feats):\n",
    "            text_ft = to_text(ft)\n",
    "            c.execute(\n",
    "              \"\"\"\n",
    "                INSERT OR IGNORE INTO feature(entity_id, feature_order, feature_text)\n",
    "                VALUES (?,?,?)\n",
    "              \"\"\",\n",
    "              (eid, order, text_ft)\n",
    "            )\n",
    "\n",
    "    conn.commit()\n",
    "    print(\"→ 实体导出完成，开始导出关系 …\")\n",
    "\n",
    "    # 导出关系边\n",
    "    for idx in range(1000):\n",
    "        src_id = idx\n",
    "        for rel in skb.rel_type_lst():\n",
    "            nbrs = skb.get_neighbor_nodes(idx, rel)\n",
    "            if not nbrs:\n",
    "                continue\n",
    "            for nbr in nbrs:\n",
    "                dst_id = nbr\n",
    "                c.execute(\n",
    "                  \"\"\"\n",
    "                    INSERT OR IGNORE INTO relation(src_id, dst_id, rel_type)\n",
    "                    VALUES (?,?,?)\n",
    "                  \"\"\",\n",
    "                  (src_id, dst_id, rel)\n",
    "                )\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"√ 导出完成，数据库保存在 {sqlite_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # skb = load_skb(name=\"amazon\", download_processed=True)\n",
    "    export_skb_to_sqlite(skb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--review\n",
      "--qa\n",
      "--asin\n",
      "--title\n",
      "--global_category\n",
      "--category\n",
      "--price\n",
      "--brand\n",
      "--feature\n",
      "--rank\n",
      "--details\n",
      "--description\n",
      "\n",
      "[{'reviewerID': 'AN5DRYRTXRBDW', 'summary': 'Looks Great', 'style': nan, 'reviewText': 'I am at the larger end of the size spectrum (size 14), and the waist band was still comfortable.', 'vote': '2', 'overall': 5.0, 'verified': True, 'reviewTime': '05 2, 2016'}, {'reviewerID': 'A2INZEU0RHYV7B', 'summary': 'Five Stars', 'style': nan, 'reviewText': 'Perfect!!', 'vote': nan, 'overall': 5.0, 'verified': True, 'reviewTime': '05 2, 2016'}, {'reviewerID': 'A3AJYZEIM88ILH', 'summary': 'Five Stars', 'style': nan, 'reviewText': 'Great color!', 'vote': nan, 'overall': 5.0, 'verified': True, 'reviewTime': '11 30, 2015'}, {'reviewerID': 'A36NU1M3F6ZD7U', 'summary': 'Three Stars', 'style': nan, 'reviewText': 'The tutu is nice, but I wish it was longer!  Thanks!', 'vote': '2', 'overall': 3.0, 'verified': True, 'reviewTime': '11 16, 2015'}, {'reviewerID': 'A38LGHDAXR0MKL', 'summary': 'One Star', 'style': nan, 'reviewText': 'Tutu smells like dead fish upon removing from packaging. After airing-out the tutu, horrible smell remained.', 'vote': nan, 'overall': 1.0, 'verified': True, 'reviewTime': '12 3, 2014'}, {'reviewerID': 'A2ZDZDXUOFQEP', 'summary': 'Five Stars', 'style': nan, 'reviewText': 'great', 'vote': nan, 'overall': 5.0, 'verified': True, 'reviewTime': '11 26, 2014'}, {'reviewerID': 'A1T8G66LD1F9RL', 'summary': 'Great tutu. My 10-year old daughter and her friends ...', 'style': nan, 'reviewText': 'Great tutu. My 10-year old daughter and her friends all got one and they were great for a Halloween costume.', 'vote': nan, 'overall': 5.0, 'verified': True, 'reviewTime': '11 15, 2014'}, {'reviewerID': 'A35ACGA2DIL1QB', 'summary': 'Not the same color pictured', 'style': nan, 'reviewText': 'Quality was fine, but the color was not the same color that was on picture, I ordered turquoise and received blue, I took pictures of the color that was on the page from seller and the actual color I received , it was not even close, could not use!', 'vote': '4', 'overall': 2.0, 'verified': True, 'reviewTime': '03 9, 2014'}]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(skb)):                 # 假设 SKB 支持按索引访问\n",
    "    node = skb[idx]\n",
    "    print(node)\n",
    "    print(node.review)\n",
    "    print(node.qa)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
